{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import normalize \n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import datasets\n",
    "from sklearn.datasets import make_circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 5620\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\"}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits = datasets.load_digits()\n",
    "digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = StandardScaler().fit_transform(digits.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 0.99,whiten = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_pca = pca.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 64\n"
     ]
    }
   ],
   "source": [
    "print(\"Original number of features:\", features.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 54\n"
     ]
    }
   ],
   "source": [
    "print(\"Original number of features:\", features_pca.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -0.33501649, -0.04308102, ..., -1.14664746,\n",
       "        -0.5056698 , -0.19600752],\n",
       "       [ 0.        , -0.33501649, -1.09493684, ...,  0.54856067,\n",
       "        -0.5056698 , -0.19600752],\n",
       "       [ 0.        , -0.33501649, -1.09493684, ...,  1.56568555,\n",
       "         1.6951369 , -0.19600752],\n",
       "       ...,\n",
       "       [ 0.        , -0.33501649, -0.88456568, ..., -0.12952258,\n",
       "        -0.5056698 , -0.19600752],\n",
       "       [ 0.        , -0.33501649, -0.67419451, ...,  0.8876023 ,\n",
       "        -0.5056698 , -0.19600752],\n",
       "       [ 0.        , -0.33501649,  1.00877481, ...,  0.8876023 ,\n",
       "        -0.26113572, -0.19600752]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.70631939, -0.39512814, -1.73816236, ...,  0.36526417,\n",
       "        -0.31369006,  0.05355504],\n",
       "       [ 0.21732591,  0.38276482,  1.72878893, ..., -0.17818068,\n",
       "        -0.14031747,  1.18179755],\n",
       "       [ 0.4804351 , -0.13130437,  1.33172761, ..., -0.01924571,\n",
       "        -0.23580029,  0.92966158],\n",
       "       ...,\n",
       "       [ 0.37732433, -0.0612296 ,  1.0879821 , ..., -1.05526847,\n",
       "         1.75559618, -0.87894699],\n",
       "       [ 0.39705007, -0.15768102, -1.08160094, ...,  0.10442881,\n",
       "         0.65907949,  1.1292155 ],\n",
       "       [-0.46407544, -0.92213976,  0.12493334, ..., -1.10593026,\n",
       "         0.54434185, -0.26573597]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features , f2 = make_circles(n_samples=1000, random_state=1, noise=0.1, factor=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpca = KernelPCA(kernel=\"rbf\", gamma=15, n_components=1)\n",
    "features_kpca = kpca.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 2\n",
      "Reduced number of features: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Original number of features:\", features.shape[1]) \n",
    "print(\"Reduced number of features:\", features_kpca.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis(n_components=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_lda = lda.fit(features,target).transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 4\n",
      "Reduced number of features: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Original number of features:\", features.shape[1]) \n",
    "print(\"Reduced number of features:\", features_lda.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\iris.csv'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 64\n",
      "Reduced number of features: 10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "from sklearn import datasets\n",
    "#Load the data\n",
    "digits = datasets.load_digits() \n",
    "#Load feature matrix\n",
    "features = digits.data\n",
    "#Create, fit, and apply NMF\n",
    "nmf = NMF(n_components=10, random_state=1)\n",
    "features_nmf = nmf.fit_transform(features)\n",
    "#Show results\n",
    "print(\"Original number of features:\", features.shape[1])\n",
    "print(\"Reduced number of features:\", features_nmf.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(features)\n",
    "dk = pd.DataFrame(features_nmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2     3     4     5    6    7    8    9   ...   54   55   56  \\\n",
       "0  0.0  0.0  5.0  13.0   9.0   1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  12.0  13.0   5.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0   4.0  15.0  12.0  0.0  0.0  0.0  0.0  ...  5.0  0.0  0.0   \n",
       "3  0.0  0.0  7.0  15.0  13.0   1.0  0.0  0.0  0.0  8.0  ...  9.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0   1.0  11.0   0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "    57   58    59    60    61   62   63  \n",
       "0  0.0  6.0  13.0  10.0   0.0  0.0  0.0  \n",
       "1  0.0  0.0  11.0  16.0  10.0  0.0  0.0  \n",
       "2  0.0  0.0   3.0  11.0  16.0  9.0  0.0  \n",
       "3  0.0  7.0  13.0  13.0   9.0  0.0  0.0  \n",
       "4  0.0  0.0   2.0  16.0   4.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.837839</td>\n",
       "      <td>0.310566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.206758</td>\n",
       "      <td>0.420320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.259290</td>\n",
       "      <td>1.208558</td>\n",
       "      <td>0.178632</td>\n",
       "      <td>0.480545</td>\n",
       "      <td>1.114120</td>\n",
       "      <td>0.208495</td>\n",
       "      <td>0.505904</td>\n",
       "      <td>0.065643</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.170202</td>\n",
       "      <td>0.795916</td>\n",
       "      <td>0.913064</td>\n",
       "      <td>1.164377</td>\n",
       "      <td>0.524886</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.303605</td>\n",
       "      <td>0.572335</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.642361</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036710</td>\n",
       "      <td>0.863136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176919</td>\n",
       "      <td>0.462489</td>\n",
       "      <td>0.460019</td>\n",
       "      <td>0.150058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.583535</td>\n",
       "      <td>0.761869</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.994703</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.289689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.530800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.000000  0.000000  0.837839  0.310566  0.000000  0.175288  0.000000   \n",
       "1  0.259290  1.208558  0.178632  0.480545  1.114120  0.208495  0.505904   \n",
       "2  0.170202  0.795916  0.913064  1.164377  0.524886  0.000000  0.303605   \n",
       "3  0.642361  0.000000  0.000000  0.036710  0.863136  0.000000  0.176919   \n",
       "4  0.000000  0.583535  0.761869  0.000000  0.994703  0.000000  0.289689   \n",
       "\n",
       "          7         8         9  \n",
       "0  0.000000  1.206758  0.420320  \n",
       "1  0.065643  0.000000  0.000000  \n",
       "2  0.572335  0.000000  0.000000  \n",
       "3  0.462489  0.460019  0.150058  \n",
       "4  0.000000  0.000000  0.530800  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dk.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
       "    n_components=10, random_state=1, shuffle=False, solver='cd', tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, cross_val_score \n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits() # Create features matrix\n",
    "features = digits.data # Create target vector\n",
    "target = digits.target # Create standardizer\n",
    "standardizer = StandardScaler()\n",
    "# Create logistic regression object\n",
    "logit = LogisticRegression()\n",
    "# Create a pipeline that standardizes, then runs logistic regression\n",
    "pipeline = make_pipeline(standardizer, logit) # Create k-Fold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "# Conduct k-fold cross-validation\n",
    "cv_results = cross_val_score(pipeline,features,target,cv=kf,scoring=\"accuracy\",n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.964931719428926"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97222222, 0.97777778, 0.95555556, 0.95      , 0.95555556,\n",
       "       0.98333333, 0.97777778, 0.96648045, 0.96089385, 0.94972067])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardizer.fit(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_std = standardizer.transform(features_train)\n",
    "features_test_std = standardizer.transform(features_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(standardizer, logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cross_val_score(pipeline, features,target, cv=kf,  scoring=\"accuracy\", n_jobs=-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.964931719428926"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = np.random.seed(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "#from sklearn.Cross_validation import cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "\n",
    "np.random.seed(6450345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(N=1000, n_vars=10,n_classes=2):\n",
    "    X = np.random.normal(size=(N,n_vars))\n",
    "    y = np.random.choice(n_classes, N)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x26766065d48>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X,y = make_data(n_vars=5)\n",
    "\n",
    "sns.heatmap(np.c_[X, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    " features, target = boston.data, boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    " features_train, features_test, target_train, target_test = train_test_split(features, target, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = DummyRegressor(strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyRegressor(constant=None, quantile=None, strategy='mean')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.001119359203955339"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols = LinearRegression()\n",
    "ols.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6354638433202129"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
